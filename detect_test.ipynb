{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb68724",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository)\n",
      "Resuming training from /home/naroo135/anaconda3/runs/train/mod/weights/last.pt\n",
      "YOLOv5 ðŸš€ v5.0-0-gf5b8f7d torch 1.10.2+cu113 CUDA:0 (Tesla V100-SXM2-16GB, 16160.6875MB)\n",
      "\n",
      "Namespace(adam=False, artifact_alias='latest', batch_size=4, bbox_interval=-1, bucket='', cache_images=False, cfg='', data='/home/naroo135/yolov5ori/yolov5/data/PBData.yaml', device='', entity=None, epochs=20, evolve=False, exist_ok=False, global_rank=-1, hyp='/home/naroo135/yolov5ori/yolov5/data/hyp.scratch.yaml', image_weights=False, img_size=[1080, 1080], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='/home/naroo135/anaconda3/runs/train/mod', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=True, save_dir='/home/naroo135/anaconda3/runs/train/mod', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=4, upload_dataset=False, weights='/home/naroo135/anaconda3/runs/train/mod/weights/last.pt', workers=8, world_size=1)\n",
      "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv5 logging with 'pip install wandb' (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      1760  models.common.Focus                     [3, 16, 3]                    \n",
      "  1                -1  1      9344  models.common.Conv                      [16, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]                \n",
      "  4                -1  1     39552  models.common.C3                        [64, 64, 3]                   \n",
      "  5                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  6                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  7                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  8                -1  1    164608  models.common.SPP                       [256, 256, [5, 9, 13]]        \n",
      "  9                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 10                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 14                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     22912  models.common.C3                        [128, 64, 1, False]           \n",
      " 18                -1  1      4224  models.common.Conv                      [64, 64, 1, 1]                \n",
      " 19                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 20           [-1, 2]  1         0  models.common.Concat                    [1]                           \n",
      " 21                -1  1     22912  models.common.C3                        [128, 64, 1, False]           \n",
      " 22                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]                \n",
      " 23          [-1, 18]  1         0  models.common.Concat                    [1]                           \n",
      " 24                -1  1     22912  models.common.C3                        [128, 64, 1, False]           \n",
      " 25                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]                \n",
      " 26          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 27                -1  1     74496  models.common.C3                        [128, 128, 1, False]          \n",
      " 28                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 29          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 30                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 31  [21, 24, 27, 30]  1     12384  models.yolo.Detect                      [3, [[6, 9, 13, 22, 24, 14], [10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [64, 64, 128, 256]]\n",
      "/home/naroo135/anaconda3/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 341 layers, 1904064 parameters, 1904064 gradients, 7.6 GFLOPS\n",
      "\n",
      "Transferred 436/436 items from /home/naroo135/anaconda3/runs/train/mod/weights/last.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "Optimizer groups: 75 .bias, 75 conv.weight, 71 other\n",
      "WARNING: --img-size 1080 must be multiple of max stride 32, updating to 1088\n",
      "WARNING: --img-size 1080 must be multiple of max stride 32, updating to 1088\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'PB_Data/modularHouse_20m_fall/labels/train.cache' images and la\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'PB_Data/modularHouse_20m_fall/labels/train.cache' images and labe\u001b[0m\n",
      "Image sizes 1088 train, 1088 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to /home/naroo135/anaconda3/runs/train/mod\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     10/19     1.61G   0.03808  0.006161   0.01578   0.06002         8      1088\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        9518       34249       0.935       0.921       0.944       0.649\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     11/19     2.22G   0.03744  0.006012   0.01567   0.05912         9      1088\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        9518       34249       0.953       0.919       0.952       0.675\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     12/19     2.22G   0.03679  0.005912   0.01562   0.05833         8      1088\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        9518       34249       0.959       0.927       0.954        0.68\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     13/19     2.22G   0.03648   0.00576   0.01549   0.05773        13      1088\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        9518       34249       0.966       0.924       0.955       0.684\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     14/19     2.22G   0.03604    0.0057   0.01543   0.05718        14      1088\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        9518       34249       0.959       0.925       0.955       0.686\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     15/19     2.22G   0.03557   0.00558   0.01538   0.05654        14      1088\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        9518       34249       0.948       0.933       0.957       0.694\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     16/19     2.22G   0.03531  0.005547   0.01528   0.05614        40      1088"
     ]
    }
   ],
   "source": [
    "!python ~/yolov5ori/yolov5/train.py --resume ~/anaconda3/runs/train/mod/weights/last.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1a2613e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/home/naroo135/anaconda3/runs/train/aug/weights/best.pt'], source=/home/naroo135/anaconda3/SARD_dataset_v6/images/train/0505.jpg/, imgsz=[1920, 1920], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=True, update=False, project=runs/detect, name=/home/naroo135/yolov5/runs/detect/gradcam_aug, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, tfl_int8=False\n",
      "YOLOv5 ðŸš€ v5.0-378-gbccc804 torch 1.10.2+cu113 CUDA:0 (Tesla V100-SXM2-16GB, 16160.6875MB)\n",
      "\n",
      "Fusing layers... \n",
      "/home/naroo135/anaconda3/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 224 layers, 7053910 parameters, 0 gradients\n",
      "image 1/1 /home/naroo135/anaconda3/SARD_dataset_v6/images/train/0505.jpg: 1088x1920 10 Persons, Done. (3.940s)\n",
      "Results saved to \u001b[1m/home/naroo135/yolov5/runs/detect/gradcam_aug9\u001b[0m\n",
      "Done. (4.083s)\n"
     ]
    }
   ],
   "source": [
    "!python ~/yolov5/detect.py --img 1920 --source ~/anaconda3/SARD_dataset_v6/images/train/0505.jpg/ --weights ~/anaconda3/runs/train/aug/weights/best.pt --name ~/yolov5/runs/detect/gradcam_aug --visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34c045e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/home/naroo135/anaconda3/runs/train/pb_mod_20/weights/best.pt'], source=/home/naroo135/anaconda3/mAP_code/public/images/20220119-001642.964527.jpg/, imgsz=[1920, 1920], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=[0, 1], agnostic_nms=False, augment=False, visualize=True, update=False, project=runs/detect, name=/home/naroo135/yolov5/runs/detect/gradcam_pb, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, tfl_int8=False\n",
      "YOLOv5 ðŸš€ v5.0-378-gbccc804 torch 1.10.2+cu113 CUDA:0 (Tesla V100-SXM2-16GB, 16160.6875MB)\n",
      "\n",
      "Fusing layers... \n",
      "/home/naroo135/anaconda3/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 256 layers, 6997696 parameters, 0 gradients\n",
      "image 1/1 /home/naroo135/anaconda3/mAP_code/public/images/20220119-001642.964527.jpg: 1088x1920 1 Person, 1 PAD, Done. (5.798s)\n",
      "Results saved to \u001b[1m/home/naroo135/yolov5/runs/detect/gradcam_pb18\u001b[0m\n",
      "Done. (6.758s)\n"
     ]
    }
   ],
   "source": [
    "!python ~/yolov5/detect.py --img 1920 --source ~/anaconda3/mAP_code/public/images/20220119-001642.964527.jpg/ --weights ~/anaconda3/runs/train/pb_ori_20/weights/best.pt --name ~/yolov5/runs/detect/gradcam_pb --visualize --classes 0 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25c0e678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/home/naroo135/anaconda3/runs/train/pb_mod_20/weights/best.pt'], source=/home/naroo135/anaconda3/PB_test/images/20220120-043456.061272.jpg/, imgsz=[1920, 1920], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=[0], agnostic_nms=False, augment=False, visualize=True, update=False, project=runs/detect, name=/home/naroo135/yolov5/runs/detect/gradcam_pb, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, tfl_int8=False\n",
      "YOLOv5 ðŸš€ v5.0-378-gbccc804 torch 1.10.2+cu113 CUDA:0 (Tesla V100-SXM2-16GB, 16160.6875MB)\n",
      "\n",
      "Fusing layers... \n",
      "/home/naroo135/anaconda3/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 256 layers, 6997696 parameters, 0 gradients\n",
      "image 1/1 /home/naroo135/anaconda3/PB_test/images/20220120-043456.061272.jpg: 1088x1920 1 Person, Done. (6.531s)\n",
      "Results saved to \u001b[1m/home/naroo135/yolov5/runs/detect/gradcam_pb19\u001b[0m\n",
      "Done. (7.068s)\n"
     ]
    }
   ],
   "source": [
    "!python ~/yolov5/detect.py --img 1920 --source ~/anaconda3/PB_test/images/20220120-043456.061272.jpg/ --weights ~/anaconda3/runs/train/pb_ori_20/weights/best.pt --name ~/yolov5/runs/detect/gradcam_pb --visualize --classes 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a419b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ~/yolov5/detect.py --img 1920 --source ~/anaconda3/PB_test_reg/images/0408.jpg/ --weights ~/anaconda3/runs/train/pb_ori_20/weights/best.pt --name ~/yolov5/runs/detect/test --visualize --classes 0 1 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
